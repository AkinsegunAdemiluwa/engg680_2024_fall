{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sU4f6NwZ0JnJ","executionInfo":{"status":"ok","timestamp":1733813366364,"user_tz":480,"elapsed":833,"user":{"displayName":"Cyprain Okafor","userId":"12075174779912435940"}},"outputId":"ed6d65f7-a532-4310-a9da-f2572745db80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mm4UZpmF0TTr","executionInfo":{"status":"ok","timestamp":1733807218017,"user_tz":420,"elapsed":145,"user":{"displayName":"Akolawole Bode-Fakunle","userId":"15138798629468836922"}},"outputId":"d0e2f044-5ed3-47c7-ee38-f3b325272f59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["%cd engg680_2024_fall"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeBkKXLx0YGs","executionInfo":{"status":"ok","timestamp":1733807219702,"user_tz":420,"elapsed":136,"user":{"displayName":"Akolawole Bode-Fakunle","userId":"15138798629468836922"}},"outputId":"4a2b1c4f-62b1-4691-8474-0b4e6471bc1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/engg680_2024_fall\n"]}]},{"cell_type":"code","source":["%cd Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhvRmV1N0gBZ","executionInfo":{"status":"ok","timestamp":1733807221198,"user_tz":420,"elapsed":134,"user":{"displayName":"Akolawole Bode-Fakunle","userId":"15138798629468836922"}},"outputId":"6264e79e-0c11-450a-ba93-38a45ddecf0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/engg680_2024_fall/Project\n"]}]},{"cell_type":"markdown","metadata":{"id":"S08tJXcT4NXQ"},"source":["# **ENGG680 - Introduction to Digital Engineering**\n","## ***PROJECT: Automated Detection of Roads and Pathways in Aerial Imagery Using Deep Learning (U-Net Model)***\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d7I0ssSD4NXT"},"source":["## Preliminary: Certificate of Work\n"]},{"cell_type":"markdown","metadata":{"id":"hcfHtIeQ4NXU"},"source":["*We, the undersigned, certify that this is our own work, which has been done expressly for this course, either without the assistance of any other party or where appropriate we have acknowledged the work of others. Further, we have read and understood the section in the university calendar on plagiarism/cheating/other academic misconduct and we are aware of the implications thereof. We request that the total mark for this assignment be distributed as follows among group members:*"]},{"cell_type":"markdown","metadata":{"id":"7EJY9e844NXW"},"source":["|          | First Name | Last Name | Signature (Full Name, Date) | Hours | Contribution % |\n","|----------|------------|-----------|-----------------------------|-------|----------------|\n","| Member 1: | Akinsegun | Ademiluwa | Akinsegun Ademiluwa, 2024-12-09 | 72 Hours | 12.5 |\n","| Member 2: | Ridwan | Sharafadeen | Ridwan Sharafadeen, 2024-12-09 | 72 Hours | 12.5 |\n","| Member 3: | Cyprain | Okafor | Cyprain Okafor, 2024-12-09 |  72 Hours | 12.5 |\n","| Member 4: | Onyeka | Emecheta | Onyeka Emecheta, 2024-12-09 | 72 Hours | 12.5 |\n","| Member 5: | Akolawole | Bode-Fakunle | Akolawole Bode-Fakunle, 2024-12-09 | 72 Hours | 12.5 |\n","| Member 6: | Victor | Fajonyomi | Victor Fajonyomi, 2024-12-09 | 72 Hours | 12.5 |\n","| Member 7: | Genevieve | Aluziwe | Genevieve Aluziwe, 2024-12-09 |  72 Hours | 12.5 |\n","| Member 8: | David | Olubiyi | David Olubiyi, 2024-12-09 | 72 Hours | 12.5 |"]},{"cell_type":"code","source":["# Define paths based on your project structure:\n","aerial_folder = \"C:/Users/AL-WASI/Desktop/ML/FUOtuoke/University of Calgary/Aerial\"\n","image_folder = os.path.join(aerial_folder, \"road_path\")\n","img_path = os.path.join(image_folder, \"img.png\")\n","mask_path = os.path.join(image_folder, \"label.png\")\n"],"metadata":{"id":"2-0rEZYAu2w7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load mask function with binary normalization:\n","def load_mask(mask_path):\n","    if not os.path.exists(mask_path):\n","        print(f\"Error: The file at {mask_path} does not exist.\")\n","        return None\n","    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    if mask is None:\n","        print(\"Error: Failed to load the mask. Check the file path or file integrity.\")\n","        return None\n","    mask = cv2.resize(mask, (256, 256))\n"],"metadata":{"id":"m4vAyRz5whXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    # Binarize mask: set all values greater than 0 to 1 (assuming binary segmentation):\n","    mask[mask > 0] = 1"],"metadata":{"id":"MOM3eIv6wl3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    # Convert mask to one-hot encoded format\n","    mask_one_hot = to_categorical(mask, num_classes=2)\n","    print(\"Mask one-hot shape:\", mask_one_hot.shape)  # Should be (256, 256, 2)\n","    return mask_one_hot"],"metadata":{"id":"BofJMm2Lwp26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set paths:\n","aerial_folder = \"C:/Users/AL-WASI/Desktop/ML/FUOtuoke/University of Calgary/Aerial\"\n","image_folder = os.path.join(aerial_folder, \"road_path\")\n","img_path = os.path.join(image_folder, \"img.png\")\n","mask_path = os.path.join(image_folder, \"label.png\")"],"metadata":{"id":"eIv9JS6PwwMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load images and masks:\n","original_image = load_image(img_path)\n","original_mask = load_mask(mask_path)\n","\n","if original_image is not None and original_mask is not None:\n","    print(\"Image and mask loaded and processed successfully.\")\n","else:\n","    print(\"Failed to load image or mask.\")"],"metadata":{"id":"WayumyyDwxVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Augmentation:\n","def augment_data(image, mask, num_augmented=10):\n","    aug = Compose([\n","        HorizontalFlip(p=0.5),\n","        VerticalFlip(p=0.5),\n","        RandomRotate90(p=0.5)\n","    ])\n","    images, masks = [image], [mask]\n","    for _ in range(num_augmented):\n","        augmented = aug(image=image, mask=mask)\n","        images.append(augmented['image'])\n","        masks.append(augmented['mask'])\n","    return np.array(images), np.array(masks)\n","\n","augmented_images, augmented_masks = augment_data(original_image, original_mask)"],"metadata":{"id":"geqNdcSIz-WN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a subset of augmented images and masks for testing\n","# Assuming you have enough samples, you can set aside some for testing:\n","split_index = int(0.8 * len(augmented_images))  # 80% for training, 20% for testing\n","train_images, test_images = augmented_images[:split_index], augmented_images[split_index:]\n","train_masks, test_masks = augmented_masks[:split_index], augmented_masks[split_index:]"],"metadata":{"id":"dqccYTiZ0IDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define UNet Model\n","def unet_model(input_size=(256, 256, 3)):\n","    inputs = Input(input_size)\n","\n","    # Down-sampling layers\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    # Bottleneck\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n","\n","    # Up-sampling layers\n","    up7 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n","    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n","\n","    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n","    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n","\n","    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n","    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n","\n","    outputs = Conv2D(2, (1, 1), activation='softmax')(conv9)\n","\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model"],"metadata":{"id":"5_0zUAOo4DQO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize and train the model\n","model = unet_model()\n","\n","# Training the model using the augmented data\n","#history = model.fit(augmented_images, augmented_masks, batch_size=4, epochs=10, validation_split=0.2)\n","# Re-train model with training split (optional if already trained)\n","history = model.fit(train_images, train_masks, batch_size=4, epochs=10, validation_split=0.2)\n"],"metadata":{"id":"qqoYt9oAE7bP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf"],"metadata":{"id":"HMGAnnIiUKbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate Model\n","def evaluate_model(model, test_images, test_masks):\n","    results = model.evaluate(test_images, test_masks, verbose=1)\n","    print(f\"Test Loss: {results[0]}\")\n","    print(f\"Test Accuracy: {results[1]}\")\n","    return results"],"metadata":{"id":"QSDrtoGrULqK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# IoU metric function\n","def iou_metric(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(y_pred, tf.float32)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n","    iou = intersection / (union + tf.keras.backend.epsilon())\n","    return iou"],"metadata":{"id":"eVSM6NJ-UP_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dice coefficient function\n","def dice_coefficient(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(y_pred, tf.float32)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    dice = (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + tf.keras.backend.epsilon())\n","    return dice"],"metadata":{"id":"X_ZARt_tUW5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate predictions and calculate IoU and Dice metrics\n","def evaluate_and_plot_predictions(model, images, masks, num_samples=3):\n","    predictions = model.predict(images)\n","    ious, dices = [], []\n","\n","    for i in range(num_samples):\n","        true_mask = masks[i]\n","        pred_mask = predictions[i]\n"],"metadata":{"id":"DdZcAjRJJXpm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate predictions and calculate IoU and Dice metrics\n","def evaluate_and_plot_predictions(model, images, masks, num_samples=3):\n","    predictions = model.predict(images)\n","    ious, dices = [], []\n","\n","    for i in range(num_samples):\n","        true_mask = masks[i]\n","        pred_mask = predictions[i]\n","\n","        # Calculate IoU and Dice metrics\n","        iou = iou_metric(true_mask, pred_mask).numpy()\n","        dice = dice_coefficient(true_mask, pred_mask).numpy()\n","        ious.append(iou)\n","        dices.append(dice)\n","\n","        print(f\"Sample {i+1} - IoU: {iou:.4f}, Dice: {dice:.4f}\")\n","\n","        # Plot images\n","        plt.figure(figsize=(15, 5))\n","\n","        # Original Image\n","        plt.subplot(1, 3, 1)\n","        plt.title(\"Original Image\")\n","        plt.imshow(images[i])\n","\n","        # Ground Truth Mask\n","        plt.subplot(1, 3, 2)\n","        plt.title(\"Ground Truth Mask\")\n","        plt.imshow(tf.argmax(true_mask, axis=-1), cmap='gray')\n","\n","        # Predicted Mask\n","        plt.subplot(1, 3, 3)\n","        plt.title(\"Predicted Mask\")\n","        predicted_mask = tf.argmax(pred_mask, axis=-1)\n","        plt.imshow(predicted_mask, cmap='gray')\n","\n","        plt.show()"],"metadata":{"id":"bBbh4XEZKDC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    # Display average metrics\n","    avg_iou = sum(ious) / len(ious)\n","    avg_dice = sum(dices) / len(dices)\n","    print(f\"Average IoU: {avg_iou:.4f}\")\n","    print(f\"Average Dice: {avg_dice:.4f}\")\n","    return avg_iou, avg_dice"],"metadata":{"id":"XJorM0WEKEF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming augmented_images and augmented_masks are divided into test_images and test_masks\n","test_images, test_masks = augmented_images[:5], augmented_masks[:5]"],"metadata":{"id":"j_Semv7hKhzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate model on test data\n","test_loss, test_acc = evaluate_model(model, test_images, test_masks)\n","avg_iou, avg_dice = evaluate_and_plot_predictions(model, test_images, test_masks)"],"metadata":{"id":"1na4Cn3YLS5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_and_visualize(model, image, true_mask):\n","    # Get the raw prediction (probabilities for each class)\n","    prediction = model.predict(np.expand_dims(image, axis=0))[0]\n","\n","    # Raw predicted mask (class with highest probability)\n","    raw_predicted_mask = np.argmax(prediction, axis=-1)\n","\n","    # Apply threshold to the predicted mask (optional adjustment)\n","    thresholded_mask = (raw_predicted_mask > 0.7).astype(np.uint8)\n","\n","    # Plot the original image, ground truth mask, and predicted mask\n","    plt.figure(figsize=(15, 5))\n","\n","    # Original Image\n","    plt.subplot(1, 3, 1)\n","    plt.title(\"Original Image\")\n","    plt.imshow(image)\n","\n","    # Ground Truth Mask\n","    plt.subplot(1, 3, 2)\n","    plt.title(\"Ground Truth Mask\")\n","    plt.imshow(np.argmax(true_mask, axis=-1), cmap='gray')\n","\n","    # Predicted Mask (thresholded)\n","    plt.subplot(1, 3, 3)\n","    plt.title(\"Predicted Mask (Thresholded)\")\n","    plt.imshow(thresholded_mask, cmap='gray')\n","\n","    # Optional: Visualize softmax output to understand model confidence\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(prediction[..., 1], cmap='hot')  # Probability for the mask class\n","    plt.colorbar()\n","    plt.title(\"Prediction Confidence\")\n","    plt.show()\n","\n","    plt.show()"],"metadata":{"id":"CSmCvPAhLWz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the image and corresponding mask\n","image_path = \"./road_path/img.png\"\n","mask_path = \"./road_path/label.png\"\n","image = load_image(image_path)\n","mask = load_mask(mask_path)"],"metadata":{"id":"-4nEEPuSLguz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now, call the prediction and visualization function\n","predict_and_visualize(model, image, mask)\n","# Plot training & validation accuracy and loss\n","def plot_training_history(history):\n","    # Summarize history for accuracy\n","    plt.figure(figsize=(12, 4))\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.title('Model Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend(loc='upper left')\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Model Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(loc='upper left')\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"HhBR2c6OLkX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming history object is returned from model\n","plot_training_history(history)"],"metadata":{"id":"O2l-kbjgLtgf"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"PROJ682_ENV","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}